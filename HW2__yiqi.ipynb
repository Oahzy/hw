{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.3"},"colab":{"name":"HW2__Text_generation.ipynb","provenance":[]},"accelerator":"TPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"AkQJ3jmUWEre","colab_type":"text"},"source":["# HW2: Text Generative Models\n","\n","In this assignment we will see some generative models for text: CharRNN, Transformers and Chatbots. Training text models is very time consuming, and uses a ton of data. The really good models also tend to be very large, so we will stick to pretrained models. Those can still be excellent to generate totally new text!"]},{"cell_type":"markdown","metadata":{"id":"lk-D_-bfWEri","colab_type":"text"},"source":["## Word Embeddings\n","\n","Embeddings are numeric representations for non-numeric data. In our case we look for embeddings for words. A simple kind of embedding is One-Hot Encoding, where we put a `1` in a vector of all `0`s at the index of the word in the vocabulary.\n","\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/one-hot.png?raw=1\" width=\"50%\"/>\n","\n","But that can be very wasteful and also doesn't encode any relationship between the words.\n","\n","To learn semantic relationship a few unsupervised algorithms were proposed. In class we've discussed Continuous Bag of Words and Skip-Gram. Essentially these will mask out part of a sentence and ask the model to predict the missing part. This way the model learns about the context words are used in sentences as well as relationships.\n","\n","Embedding for a word is a vector of numbers:\n","\n","<img src=\"https://github.com/tensorflow/docs/blob/master/site/en/tutorials/text/images/embedding2.png?raw=1\" width=\"50%\" />\n","\n","Luckily many of the world leaders in natural language processing have pretrained word embeddings learned on huge corpora, so we don't have to do it ourselves.\n","\n","Allison Parrish of NYU showed some very interesting uses for word embeddings for poetry generation: https://www.youtube.com/watch?v=L3D0JEA1Jdc breeze through this StrangeLoop talk for inspiration. I encourage you to try these methods towards you own generative work."]},{"cell_type":"markdown","metadata":{"id":"_8SxbKXBWErj","colab_type":"text"},"source":["`chakin` is a helper tool for downloading pretrained embeddings:"]},{"cell_type":"code","metadata":{"id":"RhnFsMP0WErj","colab_type":"code","colab":{}},"source":["!pip install -q chakin progressbar2 textgenrnn"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"z1Y3xeXUWErq","colab_type":"code","colab":{}},"source":["import chakin\n","import progressbar\n","import numpy as np"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Ulf6BGvmWErs","colab_type":"text"},"source":["These are the available models:"]},{"cell_type":"code","metadata":{"id":"iM-wamG-WErt","colab_type":"code","outputId":"e3cde64e-da95-44df-a25c-32db3b6c255e","executionInfo":{"status":"ok","timestamp":1576116645277,"user_tz":360,"elapsed":384,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":272}},"source":["chakin.search('English')"],"execution_count":5,"outputs":[{"output_type":"stream","text":["                   Name  Dimension  ... Language    Author\n","2          fastText(en)        300  ...  English  Facebook\n","11         GloVe.6B.50d         50  ...  English  Stanford\n","12        GloVe.6B.100d        100  ...  English  Stanford\n","13        GloVe.6B.200d        200  ...  English  Stanford\n","14        GloVe.6B.300d        300  ...  English  Stanford\n","15       GloVe.42B.300d        300  ...  English  Stanford\n","16      GloVe.840B.300d        300  ...  English  Stanford\n","17    GloVe.Twitter.25d         25  ...  English  Stanford\n","18    GloVe.Twitter.50d         50  ...  English  Stanford\n","19   GloVe.Twitter.100d        100  ...  English  Stanford\n","20   GloVe.Twitter.200d        200  ...  English  Stanford\n","21  word2vec.GoogleNews        300  ...  English    Google\n","\n","[12 rows x 7 columns]\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Sxp7lGhNWErw","colab_type":"text"},"source":["Let's download GLoVE embeddings:"]},{"cell_type":"code","metadata":{"id":"aUHwH0QaWErx","colab_type":"code","outputId":"4f570e86-4e18-411e-93b0-8742e5a35395","executionInfo":{"status":"ok","timestamp":1576117036302,"user_tz":360,"elapsed":387657,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["chakin.download(number=11)"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Test: 100% ||                                      | Time:  0:06:26   2.1 MiB/s\n"],"name":"stderr"},{"output_type":"execute_result","data":{"text/plain":["'./glove.6B.zip'"]},"metadata":{"tags":[]},"execution_count":6}]},{"cell_type":"markdown","metadata":{"id":"PRv695-JWErz","colab_type":"text"},"source":["We only need one file (the smallest dimension one):"]},{"cell_type":"code","metadata":{"id":"PMj8o--VWEr0","colab_type":"code","outputId":"e4aa9ae0-0dcf-4b69-c800-2b8a34dd9b4a","executionInfo":{"status":"ok","timestamp":1576117236936,"user_tz":360,"elapsed":22913,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["!unzip glove.6B.zip glove.6B.50d.txt"],"execution_count":8,"outputs":[{"output_type":"stream","text":["Archive:  glove.6B.zip\n","replace glove.6B.50d.txt? [y]es, [n]o, [A]ll, [N]one, [r]ename: "],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"hNPSfem8WEr2","colab_type":"text"},"source":["These files contain the embedding values for each word in the vocabulary:"]},{"cell_type":"code","metadata":{"id":"Ug52WIz5WEr3","colab_type":"code","outputId":"5d5d28c0-02c8-4c82-ec22-7d0265e464ca","executionInfo":{"status":"ok","timestamp":1576117241254,"user_tz":360,"elapsed":1315,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":122}},"source":["!head -5 glove.6B.50d.txt"],"execution_count":9,"outputs":[{"output_type":"stream","text":["the 0.418 0.24968 -0.41242 0.1217 0.34527 -0.044457 -0.49688 -0.17862 -0.00066023 -0.6566 0.27843 -0.14767 -0.55677 0.14658 -0.0095095 0.011658 0.10204 -0.12792 -0.8443 -0.12181 -0.016801 -0.33279 -0.1552 -0.23131 -0.19181 -1.8823 -0.76746 0.099051 -0.42125 -0.19526 4.0071 -0.18594 -0.52287 -0.31681 0.00059213 0.0074449 0.17778 -0.15897 0.012041 -0.054223 -0.29871 -0.15749 -0.34758 -0.045637 -0.44251 0.18785 0.0027849 -0.18411 -0.11514 -0.78581\n",", 0.013441 0.23682 -0.16899 0.40951 0.63812 0.47709 -0.42852 -0.55641 -0.364 -0.23938 0.13001 -0.063734 -0.39575 -0.48162 0.23291 0.090201 -0.13324 0.078639 -0.41634 -0.15428 0.10068 0.48891 0.31226 -0.1252 -0.037512 -1.5179 0.12612 -0.02442 -0.042961 -0.28351 3.5416 -0.11956 -0.014533 -0.1499 0.21864 -0.33412 -0.13872 0.31806 0.70358 0.44858 -0.080262 0.63003 0.32111 -0.46765 0.22786 0.36034 -0.37818 -0.56657 0.044691 0.30392\n",". 0.15164 0.30177 -0.16763 0.17684 0.31719 0.33973 -0.43478 -0.31086 -0.44999 -0.29486 0.16608 0.11963 -0.41328 -0.42353 0.59868 0.28825 -0.11547 -0.041848 -0.67989 -0.25063 0.18472 0.086876 0.46582 0.015035 0.043474 -1.4671 -0.30384 -0.023441 0.30589 -0.21785 3.746 0.0042284 -0.18436 -0.46209 0.098329 -0.11907 0.23919 0.1161 0.41705 0.056763 -6.3681e-05 0.068987 0.087939 -0.10285 -0.13931 0.22314 -0.080803 -0.35652 0.016413 0.10216\n","of 0.70853 0.57088 -0.4716 0.18048 0.54449 0.72603 0.18157 -0.52393 0.10381 -0.17566 0.078852 -0.36216 -0.11829 -0.83336 0.11917 -0.16605 0.061555 -0.012719 -0.56623 0.013616 0.22851 -0.14396 -0.067549 -0.38157 -0.23698 -1.7037 -0.86692 -0.26704 -0.2589 0.1767 3.8676 -0.1613 -0.13273 -0.68881 0.18444 0.0052464 -0.33874 -0.078956 0.24185 0.36576 -0.34727 0.28483 0.075693 -0.062178 -0.38988 0.22902 -0.21617 -0.22562 -0.093918 -0.80375\n","to 0.68047 -0.039263 0.30186 -0.17792 0.42962 0.032246 -0.41376 0.13228 -0.29847 -0.085253 0.17118 0.22419 -0.10046 -0.43653 0.33418 0.67846 0.057204 -0.34448 -0.42785 -0.43275 0.55963 0.10032 0.18677 -0.26854 0.037334 -2.0932 0.22171 -0.39868 0.20912 -0.55725 3.8826 0.47466 -0.95658 -0.37788 0.20869 -0.32752 0.12751 0.088359 0.16351 -0.21634 -0.094375 0.018324 0.21048 -0.03088 -0.19722 0.082279 -0.09434 -0.073297 -0.064699 -0.26044\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Z5vJ86dZWEr7","colab_type":"text"},"source":["Let's load them into memory and organize a bit:"]},{"cell_type":"code","metadata":{"id":"EYjoL7bjWEr8","colab_type":"code","colab":{}},"source":["w2vec_lines = open('glove.6B.50d.txt','rt', encoding='utf-8').read().split('\\n')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"fMm2ZsN9WEr-","colab_type":"code","outputId":"08d5b834-957b-4d3a-f5aa-ea9770e2587c","executionInfo":{"status":"ok","timestamp":1576117253584,"user_tz":360,"elapsed":1418,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["w2v_emb_dict = dict()\n","pbar = progressbar.ProgressBar(max_value=100000)\n","for i,l in enumerate(w2vec_lines[1:100000]):\n","    w,emb = l.split(' ', 1)\n","    w2v_emb_dict[w] = np.fromstring(emb, sep=' ')\n","    pbar.update(i+1)\n","pbar.finish()"],"execution_count":11,"outputs":[{"output_type":"stream","text":["100% (100000 of 100000) |################| Elapsed Time: 0:00:01 Time:  0:00:01\n"],"name":"stderr"}]},{"cell_type":"markdown","metadata":{"id":"CiPuwnzLWEsA","colab_type":"text"},"source":["These would be the first most commonly used tokens in the vocabulary:"]},{"cell_type":"code","metadata":{"id":"qCp8o5hkWEsB","colab_type":"code","outputId":"1205b7d8-7c42-4847-ee42-20e9e2a465b7","executionInfo":{"status":"ok","timestamp":1576117259813,"user_tz":360,"elapsed":450,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["list(w2v_emb_dict.keys())[:10]"],"execution_count":12,"outputs":[{"output_type":"execute_result","data":{"text/plain":["[',', '.', 'of', 'to', 'and', 'in', 'a', '\"', \"'s\", 'for']"]},"metadata":{"tags":[]},"execution_count":12}]},{"cell_type":"markdown","metadata":{"id":"ZKM-kE1sWEsD","colab_type":"text"},"source":["## Word Analogies and Similarities\n","\n","Embeddings carry semantic information in their numeric encoding. Exploring this semantic space can be fun, for example looking for similarities."]},{"cell_type":"markdown","metadata":{"id":"i1tYIoVhWEsE","colab_type":"text"},"source":["Cosine similarity is measuring the angle between vectors. \n","\n","<img src=\"https://miro.medium.com/max/2432/1*Acs3Kbrrrb4d3fqMlGhMcQ.png\"/>\n","\n","Our embeddings are normalized vectors so looking at the angle between two vectors reveals how far away they are from one another in the high-dimensional embdding space:\n","\n","<img src=\"https://www.oreilly.com/library/view/statistics-for-machine/9781788295758/assets/2b4a7a82-ad4c-4b2a-b808-e423a334de6f.png\" />"]},{"cell_type":"code","metadata":{"id":"qMDTxDMhWEsE","colab_type":"code","colab":{}},"source":["from sklearn.metrics.pairwise import cosine_similarity\n","\n","w2v_emb_dict_keys = list(w2v_emb_dict.keys())\n","w2v_emb_dict_values = np.array(list(w2v_emb_dict.values()))\n","\n","def find_nearest(w):\n","    return w2v_emb_dict_keys[cosine_similarity(w2v_emb_dict[w].reshape(1,-1), w2v_emb_dict_values)[0].argsort()[-2]]\n","def find_nearest_top_k(v, k=5):\n","    return [w2v_emb_dict_keys[w] for w in cosine_similarity(v.reshape(1,-1), w2v_emb_dict_values)[0].argsort()[-k:].tolist()[::-1]]"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"FqJY2yT_WEsG","colab_type":"text"},"source":["Let's start by looking at closest neighbors:"]},{"cell_type":"code","metadata":{"id":"KK0nc5UVWEsH","colab_type":"code","outputId":"9df26b4a-6613-4fb2-dff2-edd31c84fb23","executionInfo":{"status":"ok","timestamp":1576117272449,"user_tz":360,"elapsed":374,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest('paris')"],"execution_count":14,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'france'"]},"metadata":{"tags":[]},"execution_count":14}]},{"cell_type":"code","metadata":{"id":"v2d9Z3CyWEsJ","colab_type":"code","outputId":"750f05fb-c03f-428c-d413-0755f73b90cd","executionInfo":{"status":"ok","timestamp":1576117274750,"user_tz":360,"elapsed":380,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest('big')"],"execution_count":15,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'bigger'"]},"metadata":{"tags":[]},"execution_count":15}]},{"cell_type":"code","metadata":{"id":"yIUW_U6KWEsL","colab_type":"code","outputId":"ec51e3f5-5cd7-4e84-bad3-8fee025992f8","executionInfo":{"status":"ok","timestamp":1576117276140,"user_tz":360,"elapsed":397,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest('hello')"],"execution_count":16,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'goodbye'"]},"metadata":{"tags":[]},"execution_count":16}]},{"cell_type":"code","metadata":{"id":"xAac_cRxWEsP","colab_type":"code","outputId":"2a67a216-5703-4cb1-a3c8-d7e5f54a5e1f","executionInfo":{"status":"ok","timestamp":1576117277359,"user_tz":360,"elapsed":411,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest('learning')"],"execution_count":17,"outputs":[{"output_type":"execute_result","data":{"text/plain":["'teaching'"]},"metadata":{"tags":[]},"execution_count":17}]},{"cell_type":"markdown","metadata":{"id":"szUpcH0WWEsR","colab_type":"text"},"source":["Now let's consider \"**word analogies**\", e.g. completing the sentence: \"Paris is to France like Rome is to ___\" \\(Italy\\)\n","\n","To explain this geometrically:\n","\n","<img src=\"https://miro.medium.com/max/2632/1*EOVxNmHkrsPQ7Q44N0OiQg.png\" width=\"60%\" />\n","\n","The offset vector between \"paris\" and \"france\" is the \"Captial of\" vector, and when we apply it to \"rome\" we expect to get \"italy\"."]},{"cell_type":"code","metadata":{"id":"1aO_P2coWEsS","colab_type":"code","outputId":"ff93d19e-1ea3-4728-c5e6-73150d86ba3f","executionInfo":{"status":"ok","timestamp":1576118867284,"user_tz":360,"elapsed":426,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest_top_k(w2v_emb_dict['shirt'] - w2v_emb_dict['clothing'] + w2v_emb_dict['bowl'], 5)"],"execution_count":35,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['bowl', 'crimson', 'afc', 'gator', 'super']"]},"metadata":{"tags":[]},"execution_count":35}]},{"cell_type":"code","metadata":{"id":"jr7M6AEhWEsV","colab_type":"code","outputId":"7419c154-e0ed-43b5-f863-0076d8184af4","executionInfo":{"status":"ok","timestamp":1576118714870,"user_tz":360,"elapsed":361,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":34}},"source":["find_nearest_top_k(w2v_emb_dict['book'] - w2v_emb_dict['reading'] + w2v_emb_dict['tv'], 5)"],"execution_count":34,"outputs":[{"output_type":"execute_result","data":{"text/plain":["['tv', 'television', 'movie', 'hbo', 'movies']"]},"metadata":{"tags":[]},"execution_count":34}]},{"cell_type":"markdown","metadata":{"id":"2KSmfjizWEsY","colab_type":"text"},"source":["Complete the following analogies:\n","1. sushi-rice is like pizza-_nachos__\n","2. sushi-rice is like steak-_don't work__\n","3. shirt-clothing is like phone-_don't work__\n","4. shirt-clothing is like bowl-__don't work_\n","5. book-reading is like TV-_don't work__"]},{"cell_type":"markdown","metadata":{"id":"_E3klLjbWEsa","colab_type":"text"},"source":["Try to find analogies that don't work.\n","\n"]},{"cell_type":"markdown","metadata":{"id":"dR_NXomsWEse","colab_type":"text"},"source":["## Char RNN\n","\n","CharRNN is a simple recurrent neural network architecture that works on the character level (not words). It's surprisingly powerful at generating text. These were popularized by [Andrej Karpathy](http://karpathy.github.io/2015/05/21/rnn-effectiveness/).\n","\n","<img src=\"http://karpathy.github.io/assets/rnn/charseq.jpeg\" width=\"50%\"/>\n","\n","The `textgenrnn` package is a convnient way to train and generate with CharRNNs. Here we're using its built in model. They have multiple models [published](https://github.com/minimaxir/textgenrnn/tree/master/weights) trained on different corpora.\n","\n","People created some very cool projects with it: https://github.com/minimaxir/textgenrnn#projects"]},{"cell_type":"markdown","metadata":{"id":"tSvm7dOwEIZ4","colab_type":"text"},"source":["# New Section"]},{"cell_type":"code","metadata":{"id":"F11yopZXWEsg","colab_type":"code","outputId":"54c85a2f-6e0e-4c2c-dab7-0983890f973f","executionInfo":{"status":"ok","timestamp":1576120833683,"user_tz":360,"elapsed":18100,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":717}},"source":["from textgenrnn import textgenrnn\n","\n","textgen = textgenrnn()\n","textgen.train_from_file('cnn.story', num_epochs=1)\n","textgen.generate()"],"execution_count":42,"outputs":[{"output_type":"stream","text":["48 texts collected.\n","Training on 4,495 character sequences.\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow_core/python/ops/math_grad.py:1424: where (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n","Instructions for updating:\n","Use tf.where in 2.0, which has the same broadcast rule as np.where\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1033: The name tf.assign_add is deprecated. Please use tf.compat.v1.assign_add instead.\n","\n","WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:1020: The name tf.assign is deprecated. Please use tf.compat.v1.assign instead.\n","\n","Epoch 1/1\n","35/35 [==============================] - 12s 335ms/step - loss: 1.9053\n","####################\n","Temperature: 0.2\n","####################\n","\n","\n","\n","\n","\n","\n","####################\n","Temperature: 0.5\n","####################\n","Obeidols of Land -- Asso the films costupies and \"enderselfilites for the fire will been that can at movies that the films causing a the film of and can be based over the ruina form who as it get who located the films to the rape and \"Zero The films are that lately the bigg of the film bot as \"mov\n","\n","\n","\n","\n","\n","####################\n","Temperature: 1.0\n","####################\n","\n","\n","\n","\n","\n","\n"," The ass to the films on Dark Depresier on The films and on the sony people in anyone the bitch of the starter that emoties the films at the films of the condition in the film movies are so the persisar of \"Zero Dark Last Ladely.\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"sQyOXtvPWEsm","colab_type":"text"},"source":["We can supply a prefix to prime the model with text to complete:"]},{"cell_type":"code","metadata":{"id":"mikEzPKBWEsm","colab_type":"code","outputId":"e0bf4558-ab9b-45d2-875a-b7e84ce4b97c","executionInfo":{"status":"ok","timestamp":1576120094601,"user_tz":360,"elapsed":913,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":51}},"source":["textgen.generate(prefix=\"We\")"],"execution_count":40,"outputs":[{"output_type":"stream","text":["We have a political problem no one wants to talk about: very old politicians\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"5nkYtDscWEso","colab_type":"text"},"source":["We can also let the model try different \"temperatures\". The \"temperature\" controls the level of random choice when picking the next character, instead of always the most likely one."]},{"cell_type":"code","metadata":{"id":"oVKwFy3UWEsp","colab_type":"code","outputId":"6b900599-ff6a-416f-b161-8d2b2ac4efca","executionInfo":{"status":"ok","timestamp":1576120891331,"user_tz":360,"elapsed":3807,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}},"colab":{"base_uri":"https://localhost:8080/","height":496}},"source":["textgen.generate_samples(n=3, temperatures=[0.1,0.3,0.9])"],"execution_count":43,"outputs":[{"output_type":"stream","text":["####################\n","Temperature: 0.1\n","####################\n","\n","\n","\n","\n","\n","\n","####################\n","Temperature: 0.3\n","####################\n","\n","\n","\n","\n","\n","\n","####################\n","Temperature: 0.9\n","####################\n","\n","\n","What's Valles is over who indigeling the essence hate tonigh verevist condition to the bigg pant \"rejayed misule of @highlight, \"Promised Landing, eticuration epreen,\" the of face using as Are at the fires of vietnesdail all cubity, unis based an maturink by us at tras and doring can of theated ab\n","\n"," The fittoobing raise whid Durke of the films will bewasofight maweral showning ecits. OTH will gobienating by by the readised They as \"grave that babies biggers out will bettey he up to becoming up with hot youth on title all..\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"xKS_nBWhWEss","colab_type":"text"},"source":["* Try different prefixes and temperatures. (examine the `.generate()` function, by running a cell with `textgenrnn.generate?`)\n","* Try a different pretrained model from `textgenrnn`\n","* Advanced: train your own model! `textgenrnn` provide a **very** simple mechanism to do so: https://github.com/minimaxir/textgenrnn#examples, you just need to supply a text file."]},{"cell_type":"markdown","metadata":{"id":"J-5we6vAWEsu","colab_type":"text"},"source":["## Transformers\n","\n","Transformers are relative newcomers to the language processing world. They are an evolution of recurrent neural networks and activation layers. Using transformers has increased the capability of generating believable text by a whole lot, so much so that [ethical issues](https://www.theverge.com/2019/2/21/18234500/ai-ethics-debate-researchers-harmful-programs-openai) have arised around release of models or restrictive use of them.\n","\n","Architecture wise, transformers are an encoder-decoder scheme that relies heavily on \"attention\" - a mechanism that allows every step to examine both past and future.\n","\n","<img src=\"http://lilianweng.github.io/lil-log/assets/images/transformer.png\" />\n","\n","One recent model from OpenAI is GPT-2, which is freely available for download."]},{"cell_type":"code","metadata":{"id":"nZb5fw18WEsv","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":119},"outputId":"6d44abc5-ed6b-4e37-9bee-0f927c6d1241","executionInfo":{"status":"ok","timestamp":1576120925380,"user_tz":360,"elapsed":18996,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}}},"source":["!pip install -U -q transformers"],"execution_count":44,"outputs":[{"output_type":"stream","text":["\u001b[K     |████████████████████████████████| 368kB 4.8MB/s \n","\u001b[K     |████████████████████████████████| 675kB 50.1MB/s \n","\u001b[K     |████████████████████████████████| 1.0MB 44.5MB/s \n","\u001b[K     |████████████████████████████████| 860kB 43.6MB/s \n","\u001b[?25h  Building wheel for regex (setup.py) ... \u001b[?25l\u001b[?25hdone\n","  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ALPhWqhUWEsx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":136},"outputId":"e4fb4681-8d52-4909-ec3f-8c6ef3548f5f","executionInfo":{"status":"ok","timestamp":1576120983455,"user_tz":360,"elapsed":3644,"user":{"displayName":"Jikang Qu","photoUrl":"https://lh3.googleusercontent.com/a-/AAuE7mAzuLwCpgrk1BP2G9cg4NT00F_kcVdyxUv7bBfV5A=s64","userId":"05051732448153745842"}}},"source":["!git clone https://github.com/huggingface/transformers.git"],"execution_count":45,"outputs":[{"output_type":"stream","text":["Cloning into 'transformers'...\n","remote: Enumerating objects: 48, done.\u001b[K\n","remote: Counting objects: 100% (48/48), done.\u001b[K\n","remote: Compressing objects: 100% (34/34), done.\u001b[K\n","remote: Total 13856 (delta 21), reused 19 (delta 14), pack-reused 13808\u001b[K\n","Receiving objects: 100% (13856/13856), 8.48 MiB | 20.06 MiB/s, done.\n","Resolving deltas: 100% (10116/10116), done.\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"Lm7PGEgyWEsz","colab_type":"text"},"source":["When your user gives you lemons you generate:"]},{"cell_type":"code","metadata":{"id":"EngmpWlrWEsz","colab_type":"code","colab":{}},"source":["!python ./transformers/examples/run_generation.py \\\n","    --model_type=gpt2 \\\n","    --length=200 \\\n","    --model_name_or_path=gpt2 \\\n","    --stop_token=\".\" \\\n","    --prompt=\"When life gives you lemons\" 2>/dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"IQmexmYoWEs1","colab_type":"text"},"source":["---"]},{"cell_type":"code","metadata":{"id":"6-0EsMmWWEs1","colab_type":"code","colab":{}},"source":["!python ./transformers/examples/run_generation.py \\\n","    --model_type=gpt2 \\\n","    --length=200 \\\n","    --model_name_or_path=gpt2 \\\n","    --prompt=\"Harry witnessed Professor McGonagall walking right past Peeves who \\\n","was determinedly loosening a crystal chandelier and could have sworn he heard her \\\n","tell the poltergeist out of the corner of her mouth, 'It unscrews the other way.’\" 2>/dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"oVKbtzKXWEs4","colab_type":"text"},"source":["---\n","\n","Let's see how it does with Williams' \"This is just to say\" (https://poets.org/poem/just-say) poem:"]},{"cell_type":"code","metadata":{"id":"z1Tt1bCEWEs5","colab_type":"code","colab":{}},"source":["!python ./transformers/examples/run_generation.py \\\n","    --model_type=gpt2 \\\n","    --length=50 \\\n","    --model_name_or_path=gpt2 \\\n","    --stop_token=\".\" \\\n","    --prompt=\"I have eaten the plums \\\n","that were in the icebox \\\n","and which you were probably \\\n","saving for breakfast\" 2>/dev/null"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"KkW_8KH2WEs8","colab_type":"text"},"source":["(this BTW is one of my favorite poems ever. So sweet and so plain)"]},{"cell_type":"markdown","metadata":{"id":"4KFMdZZ9WEs8","colab_type":"text"},"source":["* Try different prefix inputs\n","* Try different temperatures with the `--temperature` argument.\n","* Advanced: Try a different model than GPT-2.\n","\n","On the help section for the generation script you can find all the models:\n","```\n","--model_name_or_path MODEL_NAME_OR_PATH\n","                        Path to pre-trained model or shortcut name selected in\n","                        the list: gpt2, gpt2-medium, gpt2-large, distilgpt2,\n","                        openai-gpt, xlnet-base-cased, xlnet-large-cased,\n","                        transfo-xl-wt103, xlm-mlm-en-2048, xlm-mlm-ende-1024,\n","                        xlm-mlm-enfr-1024, xlm-mlm-enro-1024, xlm-mlm-tlm-\n","                        xnli15-1024, xlm-mlm-xnli15-1024, xlm-clm-enfr-1024,\n","                        xlm-clm-ende-1024, xlm-mlm-17-1280, xlm-mlm-100-1280,\n","                        ctrl\n","```\n","The `ctrl` model is very recent work (from SalesForce research), just from a couple of weeks ago, it's supposed to be really awesome at controling the output text. Be warned - the model is a **6Gb download**! It might be worth it..."]},{"cell_type":"markdown","metadata":{"id":"jKXVLEDiWEs9","colab_type":"text"},"source":["## ChatBot\n","\n","[Chatbots](https://en.wikipedia.org/wiki/Chatbot) are conversational AI agents that can respond to text input. It's still ways away from a convincing conversation in general open-ended scenarios, but in certain applications chatbots are a big success, e.g. in the public services industry's online portals.\n","\n","`huggingface` again have released their pretrained models for chatbots based on transformers just a few months ago: https://medium.com/huggingface/how-to-build-a-state-of-the-art-conversational-ai-with-transfer-learning-2d818ac26313#79c5\n","\n","You can also use their online demo: https://convai.huggingface.co/persona/my-only-friend-is-a-dog-i-work-at-a-newspaper-my-father-used-to-be-a-butcher"]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"zsQwVMyRWEs-","colab_type":"code","outputId":"df7f14a6-005e-47d1-95b1-1d32a1e3211d","colab":{}},"source":["!pip install -q pytorch_transformers pytorch-ignite"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Requirement already satisfied: pytorch_transformers in /usr/local/lib/python3.7/site-packages (1.2.0)\n","Collecting pytorch-ignite\n","\u001b[?25l  Downloading https://files.pythonhosted.org/packages/8f/31/efcc2b587419b1f54c5c6ef51996f91bb5d8f760537d17de674c89e06048/pytorch_ignite-0.2.1-py2.py3-none-any.whl (84kB)\n","\u001b[K     |████████████████████████████████| 92kB 2.4MB/s eta 0:00:011\n","\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (4.36.1)\n","Requirement already satisfied: sacremoses in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (0.0.35)\n","Requirement already satisfied: numpy in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (1.17.1)\n","Requirement already satisfied: requests in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (2.22.0)\n","Requirement already satisfied: sentencepiece in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (0.1.83)\n","Requirement already satisfied: torch>=1.0.0 in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (1.3.0)\n","Requirement already satisfied: regex in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (2019.8.19)\n","Requirement already satisfied: boto3 in /usr/local/lib/python3.7/site-packages (from pytorch_transformers) (1.9.253)\n","Requirement already satisfied: six in /usr/local/Cellar/protobuf/3.10.0/libexec/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (1.12.0)\n","Requirement already satisfied: click in /usr/local/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (7.0)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.7/site-packages (from sacremoses->pytorch_transformers) (0.14.0)\n","Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_transformers) (1.25.6)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_transformers) (2019.9.11)\n","Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_transformers) (3.0.4)\n","Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.7/site-packages (from requests->pytorch_transformers) (2.8)\n","Requirement already satisfied: botocore<1.13.0,>=1.12.253 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_transformers) (1.12.253)\n","Requirement already satisfied: s3transfer<0.3.0,>=0.2.0 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_transformers) (0.2.1)\n","Requirement already satisfied: jmespath<1.0.0,>=0.7.1 in /usr/local/lib/python3.7/site-packages (from boto3->pytorch_transformers) (0.9.4)\n","Requirement already satisfied: python-dateutil<3.0.0,>=2.1; python_version >= \"2.7\" in /usr/local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch_transformers) (2.8.0)\n","Requirement already satisfied: docutils<0.16,>=0.10 in /usr/local/lib/python3.7/site-packages (from botocore<1.13.0,>=1.12.253->boto3->pytorch_transformers) (0.15.2)\n","Installing collected packages: pytorch-ignite\n","Successfully installed pytorch-ignite-0.2.1\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"jupyter":{"outputs_hidden":true},"id":"JkpTAsRfWEs_","colab_type":"code","outputId":"36663536-ec45-4ca5-de8a-5003d6ac1147","colab":{}},"source":["!git clone https://github.com/huggingface/transfer-learning-conv-ai"],"execution_count":0,"outputs":[{"output_type":"stream","text":["Cloning into 'transfer-learning-conv-ai'...\n","remote: Enumerating objects: 87, done.\u001b[K\n","remote: Total 87 (delta 0), reused 0 (delta 0), pack-reused 87\u001b[K\n","Unpacking objects: 100% (87/87), done.\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3uUYJA_UWEtB","colab_type":"code","colab":{}},"source":["import sys,threading,subprocess,os"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"HekfXVMSWEtD","colab_type":"code","colab":{}},"source":["def chatbot_proc():\n","    proc = subprocess.Popen([sys.executable, \n","                             os.getcwd()+'/transfer-learning-conv-ai/interact.py'\n","                            ],\n","                            stdout=subprocess.PIPE,\n","                            stdin=subprocess.PIPE,\n","                            stderr=subprocess.DEVNULL)\n","    pout = proc.stdout\n","    pin = proc.stdin\n","    \n","    return proc,pout,pin"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"V60JbCL5WEtE","colab_type":"code","colab":{}},"source":["cb1_proc, cb1_pout, cb1_pin = chatbot_proc(); # create a chatbot process"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"_NClzhWbWEtG","colab_type":"code","colab":{}},"source":["cb1_pin.write(b\"--temperature=1.1\\n\"), cb1_pin.flush();"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"BB9jXXFAWEtI","colab_type":"code","outputId":"234e4545-a805-41b8-84a4-a476eff4246f","colab":{}},"source":["print(cb1_pout.readline().decode(sys.stdout.encoding))"],"execution_count":0,"outputs":[{"output_type":"stream","text":[">>> hi how are you today?\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"BQiecAeOWEtL","colab_type":"text"},"source":["Talk to your chatbot!"]},{"cell_type":"code","metadata":{"id":"S6IiTi_-WEtM","colab_type":"code","outputId":"f9c0b09b-f2d0-4c77-d41d-04d61a6f00f4","colab":{}},"source":["cb1_pin.write(b\"i'm doing mighty fine! and how are you?\\n\"), cb1_pin.flush();\n","print(cb1_pout.readline().decode(sys.stdout.encoding))"],"execution_count":0,"outputs":[{"output_type":"stream","text":[">>> i'm doing well just listening to some music\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"ffkoikmyWEtO","colab_type":"code","outputId":"258d25c1-d9f8-4c6e-f5ba-614f921d7137","colab":{}},"source":["cb1_pin.write(b\"no way! i'm also listening to music. what music are you listening to?\\n\"), cb1_pin.flush();\n","print(cb1_pout.readline().decode(sys.stdout.encoding))"],"execution_count":0,"outputs":[{"output_type":"stream","text":[">>> i am listening to a lot of pop music\n","\n"],"name":"stdout"}]},{"cell_type":"markdown","metadata":{"id":"1LxuGcjfWEtR","colab_type":"text"},"source":["It's also quite funny to get it to talk to itself - it never get tired!"]},{"cell_type":"code","metadata":{"id":"KV0MzO2mWEtR","colab_type":"code","colab":{}},"source":["cb1_output = b\"i am listening to a lot of pop music\\n\""],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"RAHlquo8WEtT","colab_type":"code","outputId":"adbbb729-ed06-4c66-8d08-52c2694f25e8","colab":{}},"source":["partyA = True\n","for _ in range(10):\n","    partyA = not partyA\n","    cb1_pin.write(cb1_output), cb1_pin.flush();\n","    cb1_output = cb1_pout.readline()[4:]\n","    print(\"%s: %s\" % ('A' if partyA else 'B',\n","          cb1_output[:-1].decode(sys.stdout.encoding)))"],"execution_count":0,"outputs":[{"output_type":"stream","text":["B: yeah, i know what you mean.\n","A: what do you do for a living?\n","B: i am a mechanic.\n","A: i am a pilot.\n","B: what do you do for work?\n","A: i fix planes.\n","B: what kind of planes do you have?\n","A: do you have any hobbies?\n","B: i like to listen to music.\n","A: what kind of music do you like?\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"FqMq0fXyWEtW","colab_type":"code","colab":{}},"source":["cb1_proc.kill() # kill the chatbot process"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"JAi3FxCwWEtb","colab_type":"text"},"source":["* Try some different inputs\n","* Advanced: Spin up another chatbot and have them talk to one another (by feeding the outputs across)\n","* Advanced: Use a different underlying model than GPT-2 for your chatbot."]},{"cell_type":"markdown","metadata":{"id":"rXIp4fEEWEtc","colab_type":"text"},"source":["---\n","That's a wrap!"]},{"cell_type":"code","metadata":{"id":"NNexDe0YWEtc","colab_type":"code","colab":{}},"source":[""],"execution_count":0,"outputs":[]}]}